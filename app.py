import streamlit as st
import pdfplumber
import pandas as pd
import re
import io
import altair as alt

# --- 1. é é¢è¨­å®š ---
st.set_page_config(
    page_title="Mont-bell è¬ç”¨å‹éŒ„è§£æå™¨ Ver 8.0",
    page_icon="ğŸ”ï¸",
    layout="wide",
    initial_sidebar_state="expanded"
)

# --- 2. æ ¸å¿ƒè§£æé‚è¼¯ (Ver 8.0: ä¸‰å±¤æœå°‹ + æš´åŠ› 7 ç¢¼æ•¸å­—åŒ¹é…) ---
def parse_product_page(text, page_num):
    data = {}
    data['Page'] = page_num
    
    # é è™•ç†ï¼šçµ±ä¸€æ›è¡Œï¼Œç§»é™¤ BOM æˆ–æ˜¯å¥‡æ€ªçš„éš±å½¢å­—å…ƒ
    clean_text = text.replace('\r\n', '\n').strip()
    if not clean_text: return None

    lines = [l.strip() for l in clean_text.split('\n') if l.strip()]

    # --- A. Style Number çµ‚æ¥µæœå°‹ç­–ç•¥ ---
    primary_style_index = -1
    primary_style_num = ""

    # å®šç¾©ä¸åŒçš„ Regex æ¨¡å¼ (å„ªå…ˆç´šç”±é«˜åˆ°ä½)
    patterns = [
        r"Style\s*#?\s*(\d{7})",  # æ¨™æº–: Style# 1101002 (é™åˆ¶7ç¢¼æ›´ç²¾æº–)
        r"Style\s*No\.?\s*(\d{7})", # è®Šé«”: Style No. 1101002
        r"Item\s*#?\s*(\d{7})",     # è®Šé«”: Item# 1101002
        r"(?<!\d)(\d{7})(?!\d)"     # æš´åŠ›: ä»»ä½•ç¨ç«‹çš„ 7 ç¢¼æ•¸å­— (Mont-bell é‚è¼¯)
    ]

    # ç”¨ä¾†æ’é™¤èª¤åˆ¤çš„ 7 ç¢¼æ•¸å­— (ä¾‹å¦‚é›»è©±ã€æ—¥æœŸã€KJè¨»è¨˜ç·¨è™Ÿ)
    # é€™è£¡å‡è¨­å‹è™Ÿé€šå¸¸ä»¥ 11, 23, 12 é–‹é ­ (æ ¹æ“šä½ çš„å‹éŒ„è§€å¯Ÿ)
    # è‹¥ä½ çš„å‹è™Ÿç¯„åœæ›´å»£ï¼Œå¯ä»¥ç§»é™¤é€™å€‹æª¢æŸ¥
    valid_prefixes = ["11", "21", "23", "33", "04", "05", "12"] 

    found_match = False
    
    # é–‹å§‹é€è¡Œæƒæ (ç‚ºäº†æŠ“åˆ°æ­£ç¢ºçš„è¡Œè™Ÿ primary_style_index)
    for i, line in enumerate(lines):
        # å¿½ç•¥ Western Size è¡Œ
        if re.search(r"\(\s*style", line, re.IGNORECASE): continue
        if "KJ" in line: continue # å¿½ç•¥è¨»è¨˜è¡Œ

        for pat in patterns:
            matches = list(re.finditer(pat, line, re.IGNORECASE))
            for m in matches:
                candidate = m.group(1)
                
                # é©—è­‰å€™é¸äºº: å¿…é ˆæ˜¯ 7 ç¢¼
                if len(candidate) != 7: continue
                
                # é©—è­‰é–‹é ­ (å¯é¸: å¢åŠ æº–ç¢ºåº¦)
                # if not any(candidate.startswith(p) for p in valid_prefixes): continue
                
                # æ’é™¤åƒåƒ¹æ ¼çš„æ•¸å­— (é›–ç„¶åƒ¹æ ¼é€šå¸¸æœ‰é€—è™Ÿï¼Œä½†ä»¥é˜²è¬ä¸€)
                if "Â¥" in line or "MSRP" in line:
                    # é™¤éé€™è¡Œæ˜ç¢ºå¯«äº† Style
                    if "Style" not in line and "Item" not in line:
                        continue

                primary_style_index = i
                primary_style_num = candidate
                found_match = True
                break
            if found_match: break
        if found_match: break

    # å¦‚æœé€è¡Œæ‰¾ä¸åˆ°ï¼Œå˜—è©¦ã€Œå…¨æ–‡è·¨è¡Œæœå°‹ã€ (é‡å° Style# å’Œæ•¸å­—æ–·è¡Œçš„æƒ…æ³)
    if not found_match:
        # åªç”¨æœ€å¯¬é¬†çš„ pattern æ‰¾
        candidates = list(re.finditer(r"Style\s*#?\s*(\d{7})", clean_text, re.IGNORECASE))
        if candidates:
            # å–ç¬¬ä¸€å€‹æ‰¾åˆ°çš„
            match = candidates[0]
            primary_style_num = match.group(1)
            # åæŸ¥è¡Œè™Ÿ
            primary_style_index = clean_text.count('\n', 0, match.start())
            found_match = True

    if not found_match:
        return None # çœŸçš„æ‰¾ä¸åˆ°ç”¢å“

    data['Style#'] = primary_style_num

    # --- B. ç”¢å“åç¨± (åŸºæ–¼ Style# å¾€ä¸Šæ‰¾) ---
    product_name = ""
    
    # ç­–ç•¥: å¾€ä¸Šæ‰¾ 5 è¡Œä»¥å…§ï¼Œé€šå¸¸åç¨±éƒ½åœ¨é™„è¿‘
    if primary_style_index > 0:
        search_range = range(primary_style_index - 1, max(-1, primary_style_index - 6), -1)
        for k in search_range:
            curr = lines[k]
            
            # æ’é™¤é›œè¨Š
            skip_keywords = [
                "mont-bell", "Fall", "Winter", "Spring", "Summer", 
                "NEW", "REVISED", "MSRP", "Â¥", "CONFIDENTIAL", 
                "Western", "Available", "Fabric Sample", "KJ", "è¨»è¨˜"
            ]
            is_noise = False
            for kw in skip_keywords:
                if kw.lower() in curr.lower(): is_noise = True; break
            
            if re.search(r"^[A-Z]{2,3}\(.*\)$", curr): is_noise = True
            
            # æ’é™¤ç´”æ•¸å­—è¡Œ (å¯èƒ½æ˜¯é ç¢¼)
            if curr.isdigit(): is_noise = True

            if not is_noise:
                product_name = curr
                break
    
    # å¦‚æœå¾€ä¸Šæ‰¾ä¸åˆ°ï¼Œè©¦è©¦çœ‹ Style# åŒä¸€è¡Œ
    if not product_name and primary_style_index < len(lines):
        line = lines[primary_style_index]
        # ç§»é™¤ Style# åŠå…¶å¾Œé¢çš„æ•¸å­—
        clean_line = re.sub(r"Style.*?(\d{7})", "", line, flags=re.IGNORECASE).strip()
        clean_line = re.sub(r"\d{7}", "", clean_line).strip() # ç§»é™¤ç´”æ•¸å­—
        if len(clean_line) > 3 and "MSRP" not in clean_line:
            product_name = clean_line

    data['Product Name'] = product_name

    # --- C. åƒ¹æ ¼èˆ‡é‡é‡ ---
    price_match = re.search(r"MSRP\s*[Â¥ï¿¥]?\s*([\d,]+)", clean_text, re.IGNORECASE)
    alt_price = re.search(r"[Â¥ï¿¥]\s*([\d,]+)", clean_text)
    if price_match: data['MSRP'] = price_match.group(1).replace(',', '')
    elif alt_price: data['MSRP'] = alt_price.group(1).replace(',', '')
    else: data['MSRP'] = "0"

    weight_match = re.search(r"Estimated Average Weight\s*[\n]*\s*(\d+\.?\d*|TBA|Ğ¢Ğ’Ğ)", clean_text, re.IGNORECASE)
    if weight_match: data['Weight (g)'] = weight_match.group(1).replace('Ğ¢Ğ’Ğ', 'TBA')
    else: data['Weight (g)'] = ""

    # --- D. Features & Material (é€šç”¨é—œéµå­—æœå°‹) ---
    # å»ºç«‹ä¸€å€‹é—œéµå­—æ˜ å°„è¡¨ï¼Œæ‡‰å°ä¸åŒå¹´ä»½çš„å¯«æ³•
    headers = {
        "Features": ["Features", "Feature", "Functions", "Characteristics"],
        "Material": ["Material", "Materials", "Fabric", "Fabrics"]
    }
    
    stop_keywords = ["Size", "Estimated", "Last Updated", "CONFIDENTIAL", "MSRP"]
    
    # è¼”åŠ©å‡½å¼ï¼šæŠ“å–å€å¡Š
    def extract_block(target_headers):
        content = []
        is_collecting = False
        
        for line in lines:
            # æª¢æŸ¥æ˜¯å¦ç‚ºæ¨™é¡Œè¡Œ
            if any(line.strip().startswith(h) for h in target_headers):
                is_collecting = True
                continue
            
            if is_collecting:
                # æª¢æŸ¥åœæ­¢æ¢ä»¶ (é‡åˆ°å…¶ä»–å¤§æ¨™é¡Œ)
                # æª¢æŸ¥ Features æ¨™é¡Œ
                if any(line.strip().startswith(h) for h in headers["Features"]) and "Features" not in target_headers: break
                # æª¢æŸ¥ Material æ¨™é¡Œ
                if any(line.strip().startswith(h) for h in headers["Material"]) and "Material" not in target_headers: break
                # æª¢æŸ¥é€šç”¨åœæ­¢è©
                if any(line.startswith(kw) for kw in stop_keywords): break
                
                # é¡è‰²èˆ‡å°ºå¯¸éæ¿¾
                if re.search(r"^[A-Z0-9]{2,4}\([A-Za-z0-9\s]+\)", line): continue # é¡è‰²ä»£ç¢¼
                if re.search(r"^[XSML\s,]+$", line) or "Size" in line: break      # å°ºå¯¸è¡Œ

                content.append(line)
        return "\n".join(content)

    data['Features'] = extract_block(headers["Features"])
    data['Material'] = extract_block(headers["Material"])

    # --- E. Category ---
    categories = ["ALPINE CLOTHING", "INSULATION", "THERMAL", "RAIN WEAR", "SOFT SHELL", "PANTS", "BASE LAYER", "FIELD WEAR", "TRAVEL & COUNTRY", "CAP & HAT", "GLOVES", "SOCKS", "SLEEPING BAG", "FOOTWEAR", "BACKPACK", "BAG", "ACCESSORIES", "CYCLING", "SNOW GEAR", "CLIMBING", "FISHING", "PADDLE SPORTS", "DOG GEAR", "KIDS & BABY"]
    data['Category'] = "Uncategorized"
    for cat in categories:
        if cat in clean_text: data['Category'] = cat; break

    return data

# --- 3. å´é‚Šæ¬„ ---
with st.sidebar:
    st.header("æ­¥é©Ÿ 1: ä¸Šå‚³æª”æ¡ˆ")
    uploaded_files = st.file_uploader("å¯å¤šé¸ä¸Šå‚³ PDF", type="pdf", accept_multiple_files=True)
    st.info("Ver 8.0 å¼·åŠ›ç‰ˆï¼š\n1. æ”¯æ´å¤šæª”æ‰¹æ¬¡è™•ç†\n2. æš´åŠ›æœå°‹ 7 ç¢¼å‹è™Ÿ (è§£æ±ºæ ¼å¼è·‘ç‰ˆ)\n3. ç›¸å®¹ KJ è¨»è¨˜èˆ‡ä¸åŒå¹´ä»½æ ¼å¼")

# --- 4. ä¸»ç•«é¢ ---
st.title("ğŸ”ï¸ Mont-bell è¬ç”¨å‹éŒ„è§£æå™¨ (Ver 8.0)")

if uploaded_files:
    col1, col2 = st.columns([1, 5])
    with col1:
        start_btn = st.button("ğŸš€ é–‹å§‹åˆ†æ", type="primary", use_container_width=True)
    
    if start_btn:
        all_products = []
        
        # å»ºç«‹é€²åº¦æ¢å®¹å™¨
        progress_text = st.empty()
        my_bar = st.progress(0)
        
        total_pdfs = len(uploaded_files)
        
        for file_idx, uploaded_file in enumerate(uploaded_files):
            try:
                with pdfplumber.open(uploaded_file) as pdf:
                    total_pages = len(pdf.pages)
                    filename = uploaded_file.name
                    
                    for i, page in enumerate(pdf.pages):
                        # æ›´æ–°å…¨åŸŸé€²åº¦
                        current_progress = (file_idx + (i / total_pages)) / total_pdfs
                        my_bar.progress(current_progress)
                        progress_text.text(f"æ­£åœ¨è™•ç†: {filename} (ç¬¬ {i+1}/{total_pages} é )...")
                        
                        text = page.extract_text()
                        if not text: continue
                        
                        p_data = parse_product_page(text, i + 1)
                        if p_data:
                            p_data['Source File'] = filename # æ¨™è¨˜ä¾†æºæª”æ¡ˆ
                            all_products.append(p_data)
                            
            except Exception as e:
                st.error(f"æª”æ¡ˆ {uploaded_file.name} è®€å–å¤±æ•—: {e}")

        my_bar.empty()
        progress_text.empty()

        if all_products:
            df = pd.DataFrame(all_products)
            df['MSRP'] = pd.to_numeric(df['MSRP'], errors='coerce').fillna(0)
            
            st.success(f"âœ… å…¨éƒ¨åˆ†æå®Œæˆï¼å…±æ“·å– **{len(df)}** é …ç”¢å“ã€‚")
            
            # å»ºç«‹ Tabs
            tab1, tab2, tab3 = st.tabs(["ğŸ“Š ç¸½è¡¨èˆ‡ä¸‹è¼‰", "ğŸ“ˆ äº¤å‰åˆ†æ", "ğŸ› ï¸ é™¤éŒ¯æ¨¡å¼ (Debug)"])
            
            with tab1:
                st.subheader("ğŸ“‹ æ•´åˆè³‡æ–™æ¸…å–®")
                display_cols = ['Source File', 'Page', 'Category', 'Product Name', 'Style#', 'MSRP', 'Features', 'Material']
                st.dataframe(
                    df[display_cols], 
                    use_container_width=True, 
                    column_config={
                        "Features": st.column_config.TextColumn("ç‰¹é»", width="medium"),
                        "Material": st.column_config.TextColumn("æè³ª", width="medium")
                    }
                )
                
                output = io.BytesIO()
                with pd.ExcelWriter(output, engine='openpyxl') as writer:
                    df.to_excel(writer, index=False, sheet_name='All_Products')
                excel_data = output.getvalue()
                
                st.download_button(
                    label="ğŸ“¥ ä¸‹è¼‰å®Œæ•´ Excel (å«æ‰€æœ‰æª”æ¡ˆ)",
                    data=excel_data,
                    file_name="Montbell_Merged_Catalog.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                    type="primary"
                )

            with tab2:
                st.subheader("å¹´ä»½/æª”æ¡ˆäº¤å‰æ¯”å°")
                chart = alt.Chart(df).mark_bar().encode(
                    x=alt.X('Source File', title='ä¾†æºæª”æ¡ˆ'),
                    y=alt.Y('count()', title='ç”¢å“æ•¸é‡'),
                    color='Category',
                    tooltip=['Source File', 'Category', 'count()']
                ).properties(height=400)
                st.altair_chart(chart, use_container_width=True)

            with tab3:
                st.subheader("ğŸ› ï¸ åŸå§‹è³‡æ–™æª¢è¦– (ç”¨æ–¼é™¤éŒ¯)")
                st.markdown("å¦‚æœä½ ç™¼ç¾æŸé è³‡æ–™æŠ“éŒ¯ï¼Œè«‹åœ¨æ­¤æŸ¥çœ‹è©²é çš„ã€ŒåŸå§‹æ“·å–æ–‡å­—ã€ã€‚")
                
                # è®“ä½¿ç”¨è€…é¸æ“‡è¦æª¢æŸ¥çš„æª”æ¡ˆèˆ‡é æ•¸
                debug_file = st.selectbox("é¸æ“‡æª”æ¡ˆ", [f.name for f in uploaded_files])
                debug_page = st.number_input("è¼¸å…¥é ç¢¼ (1-based)", min_value=1, value=5)
                
                if st.button("æª¢è¦–åŸå§‹æ–‡å­—"):
                    # é‡æ–°è®€å–è©²é  (ç‚ºäº†é¡¯ç¤º) - é€™è£¡ç¨å¾®æ²’æ•ˆç‡ä½†åœ¨ debug æ¨¡å¼å¯æ¥å—
                    target_file_obj = next(f for f in uploaded_files if f.name == debug_file)
                    # éœ€é‡ç½® pointer
                    target_file_obj.seek(0) 
                    with pdfplumber.open(target_file_obj) as dbg_pdf:
                        if debug_page <= len(dbg_pdf.pages):
                            raw_txt = dbg_pdf.pages[debug_page-1].extract_text()
                            st.text_area("PDF Raw Text Content:", raw_txt, height=400)
                        else:
                            st.error("é ç¢¼è¶…å‡ºç¯„åœ")

        else:
            st.warning("âš ï¸ æƒæäº†æ‰€æœ‰æª”æ¡ˆï¼Œä½†æœªç™¼ç¾ç¬¦åˆæ ¼å¼çš„è³‡æ–™ã€‚è«‹åˆ‡æ›åˆ°ã€Œé™¤éŒ¯æ¨¡å¼ã€æª¢æŸ¥åŸå§‹æ–‡å­—æ˜¯å¦ç‚ºäº‚ç¢¼æˆ–åœ–ç‰‡ã€‚")