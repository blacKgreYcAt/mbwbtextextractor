import streamlit as st
import pdfplumber
import pandas as pd
import re
import io
import altair as alt

# --- 1. é é¢è¨­å®š ---
st.set_page_config(
    page_title="Mont-bell å‹éŒ„è§£æå™¨ Ver 13.0 (å¤©éš›ç·šåˆ†å±¤ç‰ˆ)",
    page_icon="ğŸ”ï¸",
    layout="wide",
    initial_sidebar_state="expanded"
)

# --- 2. æ ¸å¿ƒè§£æé‚è¼¯ (Ver 13.0: æ©«ç·šä¸Šä¸‹åˆ†å±¤æŠ“å–) ---

def find_header_separator_y(page):
    """
    åµæ¸¬é é¢ä¸»æ©«ç·š (Header Line)ã€‚
    å›å‚³ Y åº§æ¨™ã€‚
    """
    try:
        edges = page.edges
        width = page.width
        # ç¯©é¸ï¼šæ°´å¹³ç·šã€å¤ é•·ã€åœ¨ä¸ŠåŠéƒ¨
        candidates = [
            e for e in edges 
            if e['orientation'] == 'horizontal' 
            and (e['x1'] - e['x0']) > (width * 0.3)
            and e['top'] < (page.height / 2)
        ]
        if not candidates: return 0
        # æ‰¾æœ€é ä¸Šé¢çš„ä¸€æ¢ (é€šå¸¸æ¨™é¡Œä¸‹æ–¹é‚£æ¢)
        candidates.sort(key=lambda e: e['top'])
        return candidates[0]['bottom'] + 2
    except Exception:
        return 0

def parse_product_page_v13(page, page_num):
    # 1. åŸºç¤è³‡è¨Š
    width = page.width
    height = page.height
    
    # 2. æ‰¾åˆ°åˆ†ç•Œæ©«ç·š
    header_y = find_header_separator_y(page)
    # å¦‚æœæ²’æ‰¾åˆ°ç·šï¼Œé è¨­ä¸€å€‹é ‚éƒ¨ buffer (é¿å…æŠ“åˆ°æœ€ä¸Šé¢çš„é çœ‰)
    if header_y == 0: header_y = height * 0.15 

    # 3. å–å¾—æ‰€æœ‰æ–‡å­—ç‰©ä»¶
    all_words = page.extract_words(keep_blank_chars=True, x_tolerance=2, y_tolerance=2)
    
    # 4. åˆ†å±¤éæ¿¾ (é—œéµæ­¥é©Ÿ!)
    # ä¸Šå±¤æ–‡å­—ï¼šæ‰¾å“å
    words_above = [w for w in all_words if w['bottom'] <= header_y]
    # ä¸‹å±¤æ–‡å­—ï¼šæ‰¾ Style#ã€ç‰¹é»ã€æè³ª
    words_below = [w for w in all_words if w['top'] >= header_y]
    
    # è‹¥ä¸‹å±¤æ²’å­— (å¯èƒ½æ˜¯ç©ºç™½é )ï¼Œè·³é
    if not words_below: return None

    # çµ„è£ä¸‹å±¤æ–‡å­—ä¾› Regex æœå°‹
    text_below = " ".join([w['text'] for w in words_below])
    full_text_raw = page.extract_text() or "" # ç”¨æ–¼å‚™ç”¨æœå°‹

    data = {
        'Page': page_num, 
        'Category': 'Uncategorized', 
        'Product Name': '', 
        'Style#': '', 
        'MSRP': '0', 
        'Weight (g)': '', 
        'Features': '', 
        'Material': '', 
        'Description': ''
    }

    # --- A. æŠ“å– Style# (åš´æ ¼é™åˆ¶åœ¨ä¸‹å±¤) ---
    # ç­–ç•¥ï¼šåœ¨ text_below ä¸­æœå°‹ 7 ç¢¼æ•¸å­—
    # å…ˆæ‰¾ "Style#" é—œéµå­—é™„è¿‘çš„
    style_match = re.search(r"Style\s*#?\s*(\d{7})", text_below, re.IGNORECASE)
    if style_match:
        data['Style#'] = style_match.group(1)
    else:
        # æš´åŠ›æœä¸‹å±¤çš„ 7 ç¢¼ (æ’é™¤ MSRP é™„è¿‘çš„)
        candidates = list(re.finditer(r"(?<!\d)(\d{7})(?!\d)", text_below))
        for m in candidates:
            # ç°¡å–®æª¢æŸ¥å‘¨åœæœ‰æ²’æœ‰ Â¥
            snippet = text_below[max(0, m.start()-10):m.end()+10]
            if "Â¥" not in snippet and "MSRP" not in snippet:
                data['Style#'] = m.group(1)
                break
    
    if not data['Style#']: return None

    # --- B. æŠ“å– Product Name (åš´æ ¼é™åˆ¶åœ¨ä¸Šå±¤) ---
    # ç­–ç•¥ï¼šåˆ†æ words_aboveï¼Œéæ¿¾æ‰å›ºå®šé›œè¨Šï¼Œå‰©ä¸‹çš„æœ€å¾Œä¸€è¡Œé€šå¸¸æ˜¯å“å
    
    # å°‡ä¸Šå±¤æ–‡å­—è½‰æˆè¡Œ
    lines_above = words_to_lines(words_above)
    
    potential_name = ""
    # å€’æ•˜æœå°‹ (å› ç‚ºå“åé€šå¸¸æœ€é è¿‘æ©«ç·š)
    for line in reversed(lines_above):
        line = line.strip()
        
        # é›œè¨Šéæ¿¾å™¨
        skip_keywords = [
            "mont-bell", "Fall", "Winter", "Spring", "Summer", 
            "CONFIDENTIAL", "KJ", "Item", "Workbook", "Distributor",
            "Page", "Last Updated"
        ]
        is_noise = False
        for kw in skip_keywords:
            if kw.lower() in line.lower(): is_noise = True; break
        
        # éæ¿¾ç´”æ•¸å­—æˆ–æ—¥æœŸ (e.g. 2024-06-14)
        if re.search(r"\d{4}[-/]\d{2}[-/]\d{2}", line): is_noise = True
        if line.replace(" ", "").isdigit(): is_noise = True
        
        if not is_noise and len(line) > 2:
            potential_name = line
            break
            
    data['Product Name'] = potential_name

    # --- C. å®šä½ä¸‹å±¤éŒ¨é» (Features/Material) ---
    features_anchor = None
    material_anchor = None
    
    for w in words_below:
        txt = w['text'].strip()
        if txt.startswith("Feature") and features_anchor is None:
            features_anchor = w
        elif txt.startswith("Material") and material_anchor is None:
            material_anchor = w

    # --- D. æŠ“å– Description (æ•˜è¿°) ---
    # å€åŸŸï¼šæ©«ç·šä¸‹æ–¹ ~ Features æ¨™é¡Œä¸Šæ–¹
    # ä½¿ç”¨ .crop()
    try:
        desc_top = header_y
        desc_bottom = features_anchor['top'] if features_anchor else (height / 3)
        
        # åªæœ‰ç•¶ç©ºé–“è¶³å¤ æ™‚æ‰æŠ“
        if desc_bottom > desc_top + 10:
            desc_crop = page.crop((0, desc_top, width, desc_bottom))
            desc_text = desc_crop.extract_text() or ""
            
            desc_lines = []
            for line in desc_text.split('\n'):
                line = line.strip()
                # æ’é™¤ Style# è¡Œ (é›–ç„¶å®ƒåœ¨ä¸‹æ–¹ï¼Œä½†æœ‰æ™‚å€™æœƒè¢« crop é€²ä¾†)
                if data['Style#'] in line: continue
                if "Style" in line: continue
                if "MSRP" in line: continue
                
                # æŠ“å–æ•˜è¿°
                if line.startswith("â€¢") or line.startswith("â—"):
                    desc_lines.append(line)
                elif len(line) > 30 and "mont-bell" not in line:
                    desc_lines.append(line)
            data['Description'] = "\n".join(desc_lines)
    except Exception:
        pass

    # --- E. æŠ“å– Features & Material (Crop åˆ†å‰²) ---
    # è¨­å®šå€åŸŸ
    content_top = max(features_anchor['bottom'], material_anchor['bottom']) if (features_anchor and material_anchor) else desc_bottom + 10
    
    # æ‰¾åº•éƒ¨é‚Šç•Œ
    content_bottom = height
    for w in words_below:
        if w['top'] > content_top and w['text'] in ["Size", "Estimated", "Last"]:
            content_bottom = min(content_bottom, w['top'])
            
    # è¨­å®šå·¦å³åˆ†å‰²ç·š (Material æ¨™é¡Œå·¦å´)
    split_x = material_anchor['x0'] - 5 if material_anchor else (width / 2)

    try:
        # Features (å·¦ä¸‹)
        if split_x > 0 and content_bottom > content_top:
            feat_crop = page.crop((0, content_top, split_x, content_bottom))
            feat_raw = feat_crop.extract_text() or ""
            feat_clean = []
            for line in feat_raw.split('\n'):
                if re.search(r"^[A-Z0-9]{2,4}\([A-Za-z0-9\s]+\)", line): continue # éæ¿¾é¡è‰²
                if "Material" in line: continue
                feat_clean.append(line.strip())
            data['Features'] = "\n".join(feat_clean)

        # Material (å³ä¸‹)
        if width > split_x and content_bottom > content_top:
            mat_crop = page.crop((split_x, content_top, width, content_bottom))
            mat_raw = mat_crop.extract_text() or ""
            mat_clean = []
            for line in mat_raw.split('\n'):
                if re.search(r"^[A-Z0-9]{2,4}\([A-Za-z0-9\s]+\)", line): continue # éæ¿¾é¡è‰²
                if re.search(r"^[A-Z]{2}\s*$", line): continue
                if "Size" in line: break
                mat_clean.append(line.strip())
            data['Material'] = "\n".join(mat_clean)
    except Exception:
        pass

    # --- F. å…¶ä»–è³‡è¨Š (MSRP, Weight, Category) ---
    # MSRP, Weight ä¾ç„¶åœ¨ä¸‹å±¤æ–‡å­—æ‰¾
    msrp_match = re.search(r"MSRP\s*[Â¥ï¿¥]?\s*([\d,]+)", text_below, re.IGNORECASE)
    if msrp_match: data['MSRP'] = msrp_match.group(1).replace(',', '')
    
    weight_match = re.search(r"Estimated Average Weight\s*[\n]*\s*(\d+\.?\d*|TBA|Ğ¢Ğ’Ğ)", text_below, re.IGNORECASE)
    if weight_match: data['Weight (g)'] = weight_match.group(1).replace('Ğ¢Ğ’Ğ', 'TBA')
    
    # Category é€šå¸¸åœ¨æœ€ä¸Šé¢ (ç”šè‡³åœ¨æ©«ç·šä¸Šé¢)ï¼Œæ‰€ä»¥ç”¨ full_text æ‰¾
    categories = ["ALPINE CLOTHING", "INSULATION", "THERMAL", "RAIN WEAR", "SOFT SHELL", "PANTS", "BASE LAYER", "FIELD WEAR", "TRAVEL & COUNTRY", "CAP & HAT", "GLOVES", "SOCKS", "SLEEPING BAG", "FOOTWEAR", "BACKPACK", "BAG", "ACCESSORIES", "CYCLING", "SNOW GEAR", "CLIMBING", "FISHING", "PADDLE SPORTS", "DOG GEAR", "KIDS & BABY"]
    for cat in categories:
        if cat in full_text_raw: data['Category'] = cat; break

    return data

def words_to_lines(words):
    if not words: return []
    sorted_words = sorted(words, key=lambda w: (w['top'], w['x0']))
    lines = []
    current_y = -1
    line_buffer = []
    for w in sorted_words:
        if abs(w['top'] - current_y) > 5:
            if line_buffer: lines.append(" ".join([x['text'] for x in line_buffer]))
            line_buffer = []
            current_y = w['top']
        line_buffer.append(w)
    if line_buffer: lines.append(" ".join([x['text'] for x in line_buffer]))
    return lines

# --- 3. å´é‚Šæ¬„ ---
with st.sidebar:
    st.header("æ­¥é©Ÿ 1: ä¸Šå‚³æª”æ¡ˆ")
    uploaded_files = st.file_uploader("å¯å¤šé¸ä¸Šå‚³ PDF", type="pdf", accept_multiple_files=True)
    st.info("Ver 13.0 ä¿®æ­£ï¼š\n1. æ©«ç·šä¸Šæ–¹ï¼šå°ˆæ‰¾ Product Name\n2. æ©«ç·šä¸‹æ–¹ï¼šå°ˆæ‰¾ Style# (é¿é–‹åœ–æ¨™ç·¨è™Ÿ)\n3. å®Œç¾åˆ†é›¢ Features/Material")

# --- 4. ä¸»ç•«é¢ ---
st.title("ğŸ”ï¸ Mont-bell å‹éŒ„è§£æå™¨ Ver 13.0 (å¤©éš›ç·šåˆ†å±¤ç‰ˆ)")

if uploaded_files:
    col1, col2 = st.columns([1, 5])
    with col1:
        start_btn = st.button("ğŸš€ é–‹å§‹åˆ†æ", type="primary", use_container_width=True)
    
    if start_btn:
        all_products = []
        my_bar = st.progress(0)
        total_pdfs = len(uploaded_files)
        
        for file_idx, uploaded_file in enumerate(uploaded_files):
            try:
                with pdfplumber.open(uploaded_file) as pdf:
                    total_pages = len(pdf.pages)
                    filename = uploaded_file.name
                    for i, page in enumerate(pdf.pages):
                        my_bar.progress((file_idx + (i / total_pages)) / total_pdfs)
                        p_data = parse_product_page_v13(page, i + 1)
                        if p_data:
                            p_data['Source File'] = filename
                            all_products.append(p_data)
            except Exception as e:
                st.error(f"Error: {e}")

        my_bar.empty()
        
        if all_products:
            df = pd.DataFrame(all_products)
            st.success(f"âœ… å®Œæˆï¼å…±æ“·å– {len(df)} ç­†è³‡æ–™ã€‚")
            
            tab1, tab2 = st.tabs(["ğŸ“Š è³‡æ–™ç¸½è¡¨", "ğŸ› ï¸ æª¢æŸ¥å€"])
            with tab1:
                display_cols = ['Source File', 'Page', 'Category', 'Product Name', 'Style#', 'MSRP', 'Features', 'Material', 'Description']
                st.dataframe(
                    df[display_cols], 
                    use_container_width=True,
                    column_config={
                        "Product Name": st.column_config.TextColumn("Product Name (ä¸Šå±¤)", width="medium"),
                        "Style#": st.column_config.TextColumn("Style# (ä¸‹å±¤)", width="small"),
                        "Features": st.column_config.TextColumn("Features (å·¦ä¸‹)", width="medium"),
                        "Material": st.column_config.TextColumn("Material (å³ä¸‹)", width="medium"),
                    }
                )
                output = io.BytesIO()
                with pd.ExcelWriter(output, engine='openpyxl') as writer:
                    df.to_excel(writer, index=False, sheet_name='All_Products')
                st.download_button("ğŸ“¥ ä¸‹è¼‰ Excel", data=output.getvalue(), file_name="Montbell_Ver13_Skyline.xlsx", mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet", type="primary")
        else:
            st.warning("âš ï¸ æœªæ“·å–åˆ°è³‡æ–™ã€‚")