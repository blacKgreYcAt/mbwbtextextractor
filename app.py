import streamlit as st
import pdfplumber
import pandas as pd
import re
import io
import altair as alt

# --- 1. é é¢è¨­å®š ---
st.set_page_config(
    page_title="Mont-bell å‹éŒ„è§£æå™¨ Ver 10.0 (çµ•å°å€åŸŸç‰ˆ)",
    page_icon="ğŸ”ï¸",
    layout="wide",
    initial_sidebar_state="expanded"
)

# --- 2. æ ¸å¿ƒè§£æé‚è¼¯ (Ver 10.0: çµ•å°å€åŸŸé–å®š) ---
def parse_product_page_v10(page, page_num):
    """
    ä½¿ç”¨ç‰©ä»¶åº§æ¨™é€²è¡Œçµ•å°å€åŸŸåˆ‡å‰²ã€‚
    """
    # æ“·å–é é¢æ‰€æœ‰æ–‡å­—ç‰©ä»¶ (å«åº§æ¨™)
    words = page.extract_words(keep_blank_chars=True, x_tolerance=2, y_tolerance=2)
    full_text = page.extract_text() or ""
    
    if not words: return None
    
    data = {
        'Page': page_num, 
        'Category': 'Uncategorized', 
        'Product Name': '', 
        'Style#': '', 
        'MSRP': '0', 
        'Weight (g)': '', 
        'Features': '', 
        'Material': '', 
        'Description': ''
    }

    # --- A. å°‹æ‰¾é—œéµéŒ¨é» (Anchors) ---
    style_anchor = None
    features_anchor = None
    material_anchor = None
    
    # æƒææ–‡å­—ç‰©ä»¶å°‹æ‰¾åœ°æ¨™
    for w in words:
        txt = w['text'].strip()
        
        # æ‰¾ Style# (æŠ“å– Style é–‹é ­çš„ç‰©ä»¶)
        if "Style" in txt and style_anchor is None:
            style_anchor = w
        
        # æ‰¾æ¨™é¡Œ (å…è¨±æ¨¡ç³ŠåŒ¹é…ï¼Œä¾‹å¦‚ "Features" æˆ– "Feature")
        if txt.startswith("Feature") and features_anchor is None:
            features_anchor = w
        elif txt.startswith("Material") and material_anchor is None:
            material_anchor = w

    # --- B. æŠ“å– Style# (å¦‚æœéŒ¨é»æ²’æ‰¾åˆ°ï¼Œç”¨ Regex å…¨æ–‡è£œæŠ“) ---
    # å„ªå…ˆå¾å…¨æ–‡æŠ“å– 7 ç¢¼æ•¸å­—ï¼Œå› ç‚ºé€™æœ€æº–ç¢º
    style_regex = re.search(r"Style\s*#?\s*(\d{7})", full_text, re.IGNORECASE)
    if style_regex:
        data['Style#'] = style_regex.group(1)
        # å¦‚æœå‰é¢æ²’æ‰¾åˆ°éŒ¨é»ï¼Œå˜—è©¦åæ¨éŒ¨é»ä½ç½® (é›–ä¸ç²¾ç¢ºä½†å¯ç”¨)
    else:
        # æš´åŠ›æœå°‹ 7 ç¢¼
        candidates = list(re.finditer(r"(?<!\d)(\d{7})(?!\d)", full_text))
        for m in candidates:
            # æ’é™¤çœ‹èµ·ä¾†åƒåƒ¹æ ¼çš„
            if "Â¥" not in full_text[max(0, m.start()-10):m.end()+10]:
                data['Style#'] = m.group(1)
                break
    
    if not data['Style#']: return None # æ²’æœ‰å‹è™Ÿå°±è·³é

    # --- C. å®šç¾©å€åŸŸé‚Šç•Œ (Boundaries) ---
    # ä¸Šä¸‹åˆ†ç•Œç·šï¼šé è¨­ç‚ºé é¢ä¸­é–“ï¼Œè‹¥æœ‰ Features æ¨™é¡Œå‰‡ä»¥æ¨™é¡Œé ‚éƒ¨ç‚ºæº–
    split_y = features_anchor['top'] if features_anchor else (page.height / 2)
    
    # å·¦å³åˆ†ç•Œç·šï¼šFeatures å’Œ Material çš„ä¸­é–“
    if features_anchor and material_anchor:
        split_x = (features_anchor['x0'] + material_anchor['x0']) / 2
    else:
        split_x = page.width / 2 # é è¨­åˆ‡ä¸­ç·š

    # --- D. å€åŸŸ 1: ä¸ŠåŠéƒ¨ (Header Section) ---
    # åŒ…å«ï¼šCategory, Product Name, MSRP, Description
    
    # ç¯©é¸å‡ºä½æ–¼ split_y ä¹‹ä¸Šçš„æ–‡å­—ï¼Œä¸¦æŒ‰ Y è»¸æ’åº
    upper_words = [w for w in words if w['bottom'] < split_y]
    upper_lines = words_to_lines(upper_words)

    # D-1. æŠ“å– Product Name (å“å)
    # ç­–ç•¥ï¼šæ‰¾åˆ° Style# é‚£ä¸€è¡Œï¼Œç„¶å¾Œå¾€ä¸Šæ‰¾ã€Œæœ€è¿‘çš„ã€ä¸€è¡Œéé›œè¨Šæ–‡å­—
    
    # å…ˆå®šä½ Style# åœ¨å“ªä¸€è¡Œ
    style_line_idx = -1
    for i, line in enumerate(upper_lines):
        if data['Style#'] in line:
            style_line_idx = i
            break
            
    # å¦‚æœæ‰¾ä¸åˆ° Style# è¡Œ (å¯èƒ½ Style# æ˜¯ Regex æŠ“åˆ°çš„ä½† words è£¡è¢«æ‹†é–‹äº†)
    # æˆ‘å€‘å˜—è©¦æ‰¾ "Style" å­—çœ¼
    if style_line_idx == -1:
        for i, line in enumerate(upper_lines):
            if "Style" in line:
                style_line_idx = i
                break

    # é–‹å§‹å¾€ä¸Šæ‰¾å“å
    potential_name = ""
    if style_line_idx > 0:
        # å¾€ä¸Šæª¢æŸ¥æœ€å¤š 5 è¡Œ
        for k in range(style_line_idx - 1, max(-1, style_line_idx - 6), -1):
            curr_line = upper_lines[k].strip()
            
            # é›œè¨Šéæ¿¾å™¨
            skip_keywords = ["mont-bell", "Fall", "Winter", "Spring", "Summer", "CONFIDENTIAL", "KJ", "MSRP", "Â¥"]
            is_noise = False
            for kw in skip_keywords:
                if kw in curr_line: is_noise = True; break
            
            # éæ¿¾ç´”æ•¸å­—æˆ–é ç¢¼
            if curr_line.isdigit(): is_noise = True
            
            # éæ¿¾é¡è‰² (Color) ä»£ç¢¼è¡Œ (ä¾‹å¦‚ "BK(Black) RD(Red)")
            if re.search(r"[A-Z]{2,3}\([A-Za-z]+\)", curr_line): is_noise = True

            if not is_noise and len(curr_line) > 2:
                potential_name = curr_line
                break # æ‰¾åˆ°å°±åœï¼Œå› ç‚ºæœ€æ¥è¿‘ Style# çš„é€šå¸¸å°±æ˜¯å“å
    
    # å¦‚æœå¾€ä¸Šæ‰¾ä¸åˆ°ï¼Œè©¦è©¦çœ‹ Style# åŒä¸€è¡Œå‰æ–¹ (ä¾‹å¦‚ "Down Jacket Style# 1101...")
    if not potential_name and style_line_idx != -1:
        current_line = upper_lines[style_line_idx]
        if "Style" in current_line:
            pre_text = current_line.split("Style")[0].strip()
            if len(pre_text) > 3:
                potential_name = pre_text

    data['Product Name'] = potential_name

    # D-2. æŠ“å– Description (æ•˜è¿°)
    # ç­–ç•¥ï¼šåœ¨ä¸ŠåŠéƒ¨å€åŸŸä¸­ï¼ŒæŠ“å–æ‰€æœ‰ä»¥ â€¢ æˆ– â— é–‹é ­çš„è¡Œï¼Œæˆ–æ˜¯ä½æ–¼æ¨™é¡Œèˆ‡ Features ä¹‹é–“çš„é•·æ–‡å­—
    desc_lines = []
    for line in upper_lines:
        line = line.strip()
        if line.startswith("â€¢") or line.startswith("â—"):
            desc_lines.append(line)
        # æœ‰äº›æ•˜è¿°æ²’æœ‰é»é»ï¼Œä½†å¾ˆé•·ä¸”ä¸æ˜¯å“å
        elif len(line) > 40 and line != potential_name and "Style" not in line and "MSRP" not in line:
            # å†æ¬¡ç¢ºèªä¸æ˜¯é›œè¨Š
            if "mont-bell" not in line and "CONFIDENTIAL" not in line:
                desc_lines.append(line)
    
    data['Description'] = "\n".join(desc_lines)

    # --- E. å€åŸŸ 2 & 3: ä¸‹åŠéƒ¨ (Features & Material) ---
    # ç¯©é¸å‡ºä½æ–¼ split_y ä¹‹ä¸‹çš„æ–‡å­—
    # è¨­å®šä¸€å€‹åº•éƒ¨é‚Šç•Œ (é‡åˆ° Size æˆ– Estimated Weight åœæ­¢)
    footer_y = page.height
    for w in words:
        if w['top'] > split_y and (w['text'] in ["Size", "Estimated", "Last"]):
            footer_y = min(footer_y, w['top'])
    
    lower_words = [w for w in words if w['top'] > split_y and w['bottom'] < footer_y]
    lower_lines = words_to_lines(lower_words) # é€™è£¡å…ˆä¸è½‰è¡Œï¼Œå› ç‚ºè¦åˆ†å·¦å³

    # é‡å° lower_words é€²è¡Œå·¦å³åˆ†é¡
    feat_txt = []
    mat_txt = []
    
    # æˆ‘å€‘éœ€è¦å°‡ lower_words é‡æ–°çµ„è£æˆè¡Œï¼Œä½†é€™æ¬¡è¦è€ƒæ…® X åº§æ¨™
    # ç°¡å–®åšæ³•ï¼šé€å€‹ word åˆ¤æ–·
    # é€²éšåšæ³•(æ¡ç”¨)ï¼šé€è¡Œçµ„è£ï¼Œç„¶å¾Œçœ‹è©²è¡Œçš„é‡å¿ƒåœ¨å·¦é‚Šé‚„æ˜¯å³é‚Š
    
    # é€™è£¡æˆ‘å€‘é‡ç”¨ words_to_lines çš„é‚è¼¯ï¼Œä½†å°æ¯ä¸€è¡Œè¨ˆç®—å¹³å‡ X
    
    # æ‰‹å‹•çµ„è£è¡Œ
    current_y = -1
    line_buffer = []
    sorted_lower = sorted(lower_words, key=lambda w: (w['top'], w['x0']))
    
    lines_with_pos = []
    for w in sorted_lower:
        if abs(w['top'] - current_y) > 5:
            if line_buffer: lines_with_pos.append(line_buffer)
            line_buffer = []
            current_y = w['top']
        line_buffer.append(w)
    if line_buffer: lines_with_pos.append(line_buffer)

    for row in lines_with_pos:
        # è¨ˆç®—é€™ä¸€è¡Œçš„ä¸­å¿ƒé» X
        avg_x = sum([w['x0'] for w in row]) / len(row)
        line_str = " ".join([w['text'] for w in row])
        
        # å¼·åŠ›éæ¿¾é¡è‰²ä»£ç¢¼ (é€™æ˜¯ä½ çš„ç—›é»)
        if re.search(r"^[A-Z0-9]{2,4}\([A-Za-z0-9\s]+\)", line_str): continue
        if re.search(r"^[A-Z]{2}\s*$", line_str): continue # å–®ç¨çš„å…©å€‹å¤§å¯«å­—æ¯
        
        # åˆ†å·¦å³
        if avg_x < split_x:
            feat_txt.append(line_str)
        else:
            mat_txt.append(line_str)

    data['Features'] = "\n".join(feat_txt)
    data['Material'] = "\n".join(mat_txt)

    # --- F. å…¶ä»–è³‡è¨Šè£œå®Œ ---
    # MSRP
    msrp_match = re.search(r"MSRP\s*[Â¥ï¿¥]?\s*([\d,]+)", full_text, re.IGNORECASE)
    if msrp_match: data['MSRP'] = msrp_match.group(1).replace(',', '')
    
    # Weight
    weight_match = re.search(r"Estimated Average Weight\s*[\n]*\s*(\d+\.?\d*|TBA|Ğ¢Ğ’Ğ)", full_text, re.IGNORECASE)
    if weight_match: data['Weight (g)'] = weight_match.group(1).replace('Ğ¢Ğ’Ğ', 'TBA')
    
    # Category
    categories = ["ALPINE CLOTHING", "INSULATION", "THERMAL", "RAIN WEAR", "SOFT SHELL", "PANTS", "BASE LAYER", "FIELD WEAR", "TRAVEL & COUNTRY", "CAP & HAT", "GLOVES", "SOCKS", "SLEEPING BAG", "FOOTWEAR", "BACKPACK", "BAG", "ACCESSORIES", "CYCLING", "SNOW GEAR", "CLIMBING", "FISHING", "PADDLE SPORTS", "DOG GEAR", "KIDS & BABY"]
    for cat in categories:
        if cat in full_text: data['Category'] = cat; break

    return data

def words_to_lines(words):
    """å°‡æ–‡å­—ç‰©ä»¶åˆ—è¡¨è½‰æ›ç‚ºç´”æ–‡å­—è¡Œåˆ—è¡¨ (ä¾ Y è»¸åˆ†çµ„)"""
    if not words: return []
    # å…ˆæŒ‰ Y æ’åºï¼Œå†æŒ‰ X æ’åº
    sorted_words = sorted(words, key=lambda w: (w['top'], w['x0']))
    lines = []
    current_y = -1
    line_buffer = []
    
    for w in sorted_words:
        # å¦‚æœ Y è»¸å·®è·è¶…é 5ï¼Œè¦–ç‚ºæ›è¡Œ
        if abs(w['top'] - current_y) > 5:
            if line_buffer:
                lines.append(" ".join([x['text'] for x in line_buffer]))
            line_buffer = []
            current_y = w['top']
        line_buffer.append(w)
    
    if line_buffer:
        lines.append(" ".join([x['text'] for x in line_buffer]))
    return lines

# --- 3. å´é‚Šæ¬„ ---
with st.sidebar:
    st.header("æ­¥é©Ÿ 1: ä¸Šå‚³æª”æ¡ˆ")
    uploaded_files = st.file_uploader("å¯å¤šé¸ä¸Šå‚³ PDF", type="pdf", accept_multiple_files=True)
    st.info("Ver 10.0 ä¿®æ­£ï¼š\n1. çµ•å°å€åŸŸé–å®š (Strict Zoning)\n2. ä¿®æ­£å“åæŠ“å–é‚è¼¯ (Style# ä¸Šæ–¹æœå°‹)\n3. å¾¹åº•åˆ†é›¢æè³ªèˆ‡æ•˜è¿°")

# --- 4. ä¸»ç•«é¢ ---
st.title("ğŸ”ï¸ Mont-bell å‹éŒ„è§£æå™¨ Ver 10.0 (çµ•å°å€åŸŸç‰ˆ)")

if uploaded_files:
    col1, col2 = st.columns([1, 5])
    with col1:
        start_btn = st.button("ğŸš€ é–‹å§‹åˆ†æ", type="primary", use_container_width=True)
    
    if start_btn:
        all_products = []
        progress_text = st.empty()
        my_bar = st.progress(0)
        total_pdfs = len(uploaded_files)
        
        for file_idx, uploaded_file in enumerate(uploaded_files):
            try:
                with pdfplumber.open(uploaded_file) as pdf:
                    total_pages = len(pdf.pages)
                    filename = uploaded_file.name
                    
                    for i, page in enumerate(pdf.pages):
                        current_progress = (file_idx + (i / total_pages)) / total_pdfs
                        my_bar.progress(current_progress)
                        progress_text.text(f"è™•ç†ä¸­: {filename} (é é¢ {i+1}/{total_pages})...")
                        
                        p_data = parse_product_page_v10(page, i + 1)
                        
                        if p_data:
                            p_data['Source File'] = filename
                            all_products.append(p_data)
                            
            except Exception as e:
                st.error(f"Error processing {uploaded_file.name}: {e}")

        my_bar.empty()
        progress_text.empty()

        if all_products:
            df = pd.DataFrame(all_products)
            
            st.success(f"âœ… åˆ†æå®Œæˆï¼å…±æ“·å– {len(df)} ç­†è³‡æ–™ã€‚")
            
            tab1, tab2 = st.tabs(["ğŸ“Š è³‡æ–™ç¸½è¡¨", "ğŸ› ï¸ åŸå§‹è³‡æ–™æª¢è¦–"])
            
            with tab1:
                display_cols = ['Source File', 'Page', 'Category', 'Product Name', 'Style#', 'MSRP', 'Features', 'Material', 'Description']
                st.dataframe(
                    df[display_cols], 
                    use_container_width=True,
                    column_config={
                        "Features": st.column_config.TextColumn("Features (å·¦ä¸‹)", width="medium"),
                        "Material": st.column_config.TextColumn("Material (å³ä¸‹)", width="medium"),
                        "Description": st.column_config.TextColumn("Description (ä¸Šæ–¹)", width="large"),
                        "Product Name": st.column_config.TextColumn("Product Name", width="medium"),
                    }
                )
                
                output = io.BytesIO()
                with pd.ExcelWriter(output, engine='openpyxl') as writer:
                    df.to_excel(writer, index=False, sheet_name='All_Products')
                excel_data = output.getvalue()
                st.download_button("ğŸ“¥ ä¸‹è¼‰ Excel", data=excel_data, file_name="Montbell_Ver10_Zoning.xlsx", mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet", type="primary")

        else:
            st.warning("âš ï¸ æœªæ“·å–åˆ°è³‡æ–™ã€‚")