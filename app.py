import streamlit as st
import pdfplumber
import pandas as pd
import re
import io
import altair as alt

# --- 1. é é¢è¨­å®š ---
st.set_page_config(
    page_title="Mont-bell å‹éŒ„è§£æå™¨ Ver 11.0 (æ‰‹è¡“åˆ€åˆ‡å‰²ç‰ˆ)",
    page_icon="ğŸ”ï¸",
    layout="wide",
    initial_sidebar_state="expanded"
)

# --- 2. æ ¸å¿ƒè§£æé‚è¼¯ (Ver 11.0: ä½¿ç”¨ .crop() ç‰©ç†åˆ†é›¢å·¦å³æ¬„) ---
def parse_product_page_v11(page, page_num):
    """
    ä½¿ç”¨ page.crop() é‡å°ç‰¹å®šå€åŸŸé€²è¡Œç¨ç«‹æ–‡å­—èƒå–ï¼Œå¾¹åº•è§£æ±ºå·¦å³æ¬„æ··åˆå•é¡Œã€‚
    """
    # 1. å–å¾—é é¢åŸºç¤è³‡è¨Š
    width = page.width
    height = page.height
    full_text = page.extract_text() or ""
    
    # æ“·å–å–®å­—ç‰©ä»¶ç”¨æ–¼å®šä½
    words = page.extract_words(keep_blank_chars=True, x_tolerance=2, y_tolerance=2)
    if not words: return None

    data = {
        'Page': page_num, 
        'Category': 'Uncategorized', 
        'Product Name': '', 
        'Style#': '', 
        'MSRP': '0', 
        'Weight (g)': '', 
        'Features': '', 
        'Material': '', 
        'Description': ''
    }

    # --- A. å®šä½é—œéµéŒ¨é» (Anchors) ---
    style_anchor = None
    features_anchor = None
    material_anchor = None
    
    for w in words:
        txt = w['text'].strip()
        # æ‰¾ Style#
        if "Style" in txt and style_anchor is None:
            style_anchor = w
        # æ‰¾æ¨™é¡Œ
        if txt.startswith("Feature") and features_anchor is None:
            features_anchor = w
        elif txt.startswith("Material") and material_anchor is None:
            material_anchor = w

    # --- B. æŠ“å– Style# (å„ªå…ˆä½¿ç”¨å…¨æ–‡ Regex) ---
    # é€™æ˜¯æœ€ç©©çš„æ–¹æ³•
    style_regex = re.search(r"Style\s*#?\s*(\d{7})", full_text, re.IGNORECASE)
    if style_regex:
        data['Style#'] = style_regex.group(1)
    else:
        # æš´åŠ›æœå°‹ 7 ç¢¼
        candidates = list(re.finditer(r"(?<!\d)(\d{7})(?!\d)", full_text))
        for m in candidates:
            if "Â¥" not in full_text[max(0, m.start()-10):m.end()+10]:
                data['Style#'] = m.group(1)
                break
    
    if not data['Style#']: return None

    # --- C. å®šç¾©ã€Œä¸Šæ–¹å€åŸŸã€ (Header Section) ---
    # åˆ†ç•Œç·šï¼šFeatures æ¨™é¡Œçš„ä¸Šæ–¹ (å¦‚æœæ²’æ‰¾åˆ°ï¼Œå°±æŠ“é é¢ 1/3 è™•)
    split_y_top = features_anchor['top'] if features_anchor else (height / 3)
    
    # C-1. æŠ“å– Product Name (å“å)
    # ç­–ç•¥ï¼šé–å®š Style# åº§æ¨™ï¼Œå¾€ä¸Šæ‰¾
    if style_anchor:
        style_top = style_anchor['top']
        # ç¯©é¸å‡ºä½æ–¼ Style# ä¸Šæ–¹ä¸”åœ¨åŒä¸€å€å¡Šçš„æ–‡å­—
        potential_lines = [w for w in words if w['bottom'] <= style_top + 5] # +5 å®¹è¨±èª¤å·®
        # è½‰æˆè¡Œ
        header_lines = words_to_lines(potential_lines)
        
        # å€’æ•˜æœå°‹ (é›¢ Style# æœ€è¿‘çš„)
        found_name = ""
        for line in reversed(header_lines):
            line = line.strip()
            # é›œè¨Šéæ¿¾
            if "Style" in line: continue # è·³é Style# æœ¬èº«è¡Œ
            if any(x in line for x in ["mont-bell", "Fall", "Winter", "CONFIDENTIAL", "KJ", "MSRP", "Â¥"]): continue
            if re.search(r"^[A-Z]{2,3}\(.*\)", line): continue # é¡è‰²ä»£ç¢¼
            if line.isdigit(): continue
            
            if len(line) > 2:
                found_name = line
                break
        data['Product Name'] = found_name
    
    # è‹¥ä¸Šæ–¹æ‰¾ä¸åˆ°ï¼Œè©¦è©¦çœ‹ Style# åŒä¸€è¡Œ
    if not data['Product Name'] and style_anchor:
        # æ‰¾å‡ºèˆ‡ Style# å·®ä¸å¤šé«˜åº¦çš„æ–‡å­—
        same_line_words = [w['text'] for w in words if abs(w['top'] - style_anchor['top']) < 5]
        line_str = " ".join(same_line_words)
        if "Style" in line_str:
            pre_text = line_str.split("Style")[0].strip()
            if len(pre_text) > 3: data['Product Name'] = pre_text

    # C-2. æŠ“å– Description (æ•˜è¿°)
    # ç¯„åœï¼šPage Top ~ Features Header Top
    # ä½¿ç”¨ .crop() æŠ“å–ä¸Šæ–¹ç´”æ–‡å­—ï¼Œé¿å…æ ¼å¼å¹²æ“¾
    try:
        header_box = (0, 0, width, split_y_top)
        header_crop = page.crop(header_box)
        header_text = header_crop.extract_text() or ""
        
        desc_lines = []
        for line in header_text.split('\n'):
            line = line.strip()
            if line.startswith("â€¢") or line.startswith("â—"):
                desc_lines.append(line)
            # è£œæŠ“é•·æ•˜è¿°
            elif len(line) > 40 and "Style" not in line and "MSRP" not in line and data['Product Name'] not in line:
                if "mont-bell" not in line:
                    desc_lines.append(line)
        data['Description'] = "\n".join(desc_lines)
    except Exception:
        pass # Crop å¤±æ•—å°±è·³é

    # --- D. å®šç¾©ã€Œä¸‹æ–¹å€åŸŸã€ (Features & Material) - æ‰‹è¡“åˆ€åˆ‡å‰² ---
    
    # 1. ç¢ºå®š Y è»¸ç¯„åœ
    # ä¸Šç•Œï¼šæ¨™é¡Œåº•éƒ¨
    top_y = max(features_anchor['bottom'], material_anchor['bottom']) if (features_anchor and material_anchor) else split_y_top + 10
    
    # ä¸‹ç•Œï¼šæ‰¾åˆ° "Size" æˆ– "Estimated" çš„ä½ç½®
    bottom_y = height
    for w in words:
        if w['top'] > top_y and w['text'] in ["Size", "Estimated", "Last"]:
            bottom_y = min(bottom_y, w['top'])
    
    # 2. ç¢ºå®š X è»¸åˆ‡å‰²ç·š
    # ä»¥ Material æ¨™é¡Œçš„å·¦é‚Šç•Œç‚ºæº–ï¼Œç¨å¾®å¾€å·¦ç•™ä¸€é» buffer (ä¾‹å¦‚ 5px)
    split_x = material_anchor['x0'] - 5 if material_anchor else (width / 2)

    # 3. åŸ·è¡Œåˆ‡å‰²èˆ‡èƒå– (Crucial Step!)
    try:
        # --- å·¦é‚Šï¼šFeatures ---
        # ç¯„åœï¼š(0, top_y, split_x, bottom_y)
        # æª¢æŸ¥åº§æ¨™åˆæ³•æ€§
        if split_x > 0 and bottom_y > top_y:
            feat_box = (0, top_y, split_x, bottom_y)
            feat_crop = page.crop(feat_box)
            # ä½¿ç”¨ layout=True å˜—è©¦ä¿æŒæ ¼å¼ï¼Œæˆ–é è¨­
            feat_raw = feat_crop.extract_text() or ""
            
            # æ¸…æ´— Features æ–‡å­—
            feat_clean = []
            for line in feat_raw.split('\n'):
                if re.search(r"^[A-Z0-9]{2,4}\([A-Za-z0-9\s]+\)", line): continue # é¡è‰²ä»£ç¢¼
                if "Material" in line: continue # æ¨™é¡Œèª¤å…¥
                feat_clean.append(line.strip())
            data['Features'] = "\n".join(feat_clean)

        # --- å³é‚Šï¼šMaterial ---
        # ç¯„åœï¼š(split_x, top_y, width, bottom_y)
        if width > split_x and bottom_y > top_y:
            mat_box = (split_x, top_y, width, bottom_y)
            mat_crop = page.crop(mat_box)
            mat_raw = mat_crop.extract_text() or ""
            
            # æ¸…æ´— Material æ–‡å­—
            mat_clean = []
            for line in mat_raw.split('\n'):
                if re.search(r"^[A-Z0-9]{2,4}\([A-Za-z0-9\s]+\)", line): continue # é¡è‰²ä»£ç¢¼
                if re.search(r"^[A-Z]{2}\s*$", line): continue
                if "Size" in line: break # ç¢°åˆ° Size åœæ­¢
                mat_clean.append(line.strip())
            data['Material'] = "\n".join(mat_clean)

    except Exception as e:
        # å¦‚æœ crop å¤±æ•— (ä¾‹å¦‚åº§æ¨™éŒ¯èª¤)ï¼Œä¸è®“ç¨‹å¼å´©æ½°ï¼Œä¿ç•™ç©ºç™½
        print(f"Crop error: {e}")

    # --- E. å…¶ä»–è³‡è¨Š ---
    # MSRP
    msrp_match = re.search(r"MSRP\s*[Â¥ï¿¥]?\s*([\d,]+)", full_text, re.IGNORECASE)
    if msrp_match: data['MSRP'] = msrp_match.group(1).replace(',', '')
    
    # Weight
    weight_match = re.search(r"Estimated Average Weight\s*[\n]*\s*(\d+\.?\d*|TBA|Ğ¢Ğ’Ğ)", full_text, re.IGNORECASE)
    if weight_match: data['Weight (g)'] = weight_match.group(1).replace('Ğ¢Ğ’Ğ', 'TBA')
    
    # Category
    categories = ["ALPINE CLOTHING", "INSULATION", "THERMAL", "RAIN WEAR", "SOFT SHELL", "PANTS", "BASE LAYER", "FIELD WEAR", "TRAVEL & COUNTRY", "CAP & HAT", "GLOVES", "SOCKS", "SLEEPING BAG", "FOOTWEAR", "BACKPACK", "BAG", "ACCESSORIES", "CYCLING", "SNOW GEAR", "CLIMBING", "FISHING", "PADDLE SPORTS", "DOG GEAR", "KIDS & BABY"]
    for cat in categories:
        if cat in full_text: data['Category'] = cat; break

    return data

def words_to_lines(words):
    if not words: return []
    sorted_words = sorted(words, key=lambda w: (w['top'], w['x0']))
    lines = []
    current_y = -1
    line_buffer = []
    for w in sorted_words:
        if abs(w['top'] - current_y) > 5:
            if line_buffer: lines.append(" ".join([x['text'] for x in line_buffer]))
            line_buffer = []
            current_y = w['top']
        line_buffer.append(w)
    if line_buffer: lines.append(" ".join([x['text'] for x in line_buffer]))
    return lines

# --- 3. å´é‚Šæ¬„ ---
with st.sidebar:
    st.header("æ­¥é©Ÿ 1: ä¸Šå‚³æª”æ¡ˆ")
    uploaded_files = st.file_uploader("å¯å¤šé¸ä¸Šå‚³ PDF", type="pdf", accept_multiple_files=True)
    st.info("Ver 11.0 ä¿®æ­£ï¼š\nä½¿ç”¨ .crop() æŠ€è¡“ç‰©ç†åˆ†å‰²å·¦å³æ¬„ä½ï¼Œä¿è­‰ç‰¹é»èˆ‡æè³ªè³‡æ–™çµ•ä¸æ··åˆã€‚")

# --- 4. ä¸»ç•«é¢ ---
st.title("ğŸ”ï¸ Mont-bell å‹éŒ„è§£æå™¨ Ver 11.0 (æ‰‹è¡“åˆ€åˆ‡å‰²ç‰ˆ)")

if uploaded_files:
    col1, col2 = st.columns([1, 5])
    with col1:
        start_btn = st.button("ğŸš€ é–‹å§‹åˆ†æ", type="primary", use_container_width=True)
    
    if start_btn:
        all_products = []
        my_bar = st.progress(0)
        total_pdfs = len(uploaded_files)
        
        for file_idx, uploaded_file in enumerate(uploaded_files):
            try:
                with pdfplumber.open(uploaded_file) as pdf:
                    total_pages = len(pdf.pages)
                    filename = uploaded_file.name
                    for i, page in enumerate(pdf.pages):
                        my_bar.progress((file_idx + (i / total_pages)) / total_pdfs)
                        p_data = parse_product_page_v11(page, i + 1)
                        if p_data:
                            p_data['Source File'] = filename
                            all_products.append(p_data)
            except Exception as e:
                st.error(f"Error: {e}")

        my_bar.empty()
        
        if all_products:
            df = pd.DataFrame(all_products)
            st.success(f"âœ… å®Œæˆï¼å…±æ“·å– {len(df)} ç­†è³‡æ–™ã€‚")
            
            tab1, tab2 = st.tabs(["ğŸ“Š è³‡æ–™ç¸½è¡¨", "ğŸ› ï¸ æª¢æŸ¥å€"])
            with tab1:
                display_cols = ['Source File', 'Page', 'Category', 'Product Name', 'Style#', 'MSRP', 'Features', 'Material', 'Description']
                st.dataframe(
                    df[display_cols], 
                    use_container_width=True,
                    column_config={
                        "Features": st.column_config.TextColumn("Features (å·¦)", width="medium"),
                        "Material": st.column_config.TextColumn("Material (å³)", width="medium"),
                        "Description": st.column_config.TextColumn("Description (ä¸Š)", width="large"),
                    }
                )
                output = io.BytesIO()
                with pd.ExcelWriter(output, engine='openpyxl') as writer:
                    df.to_excel(writer, index=False, sheet_name='All_Products')
                st.download_button("ğŸ“¥ ä¸‹è¼‰ Excel", data=output.getvalue(), file_name="Montbell_Ver11_Crop.xlsx", mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet", type="primary")
        else:
            st.warning("âš ï¸ æœªæ“·å–åˆ°è³‡æ–™ã€‚")